{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c1bce28-f926-4b42-93a3-ba0daac61f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyodbc in c:\\users\\pavan\\anaconda3\\lib\\site-packages (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyodbc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b3b607b-11b6-43b0-8c36-a731635cbdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0762d857-7a51-4ebd-83c3-d28323f42652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Connected to SQL Server\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define your SQL Server connection\n",
    "conn_str = \"\"\"\n",
    "DRIVER={ODBC Driver 17 for SQL Server};\n",
    "SERVER=PAVAN_KUMAR_CH\\\\SQLEXPRESS;\n",
    "DATABASE=HairSalonDB;\n",
    "Trusted_Connection=yes;\n",
    "\"\"\"\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "print(\" Connected to SQL Server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec211900-57fd-4521-aefd-47713474712d",
   "metadata": {},
   "source": [
    "# CSV URL to SQL Table mapping\n",
    "csv_table_mapping = {\n",
    "    \n",
    "    \"https://storage.googleapis.com/data_migration_pr1/Future%20Bookings%20(All%20Clients)0.csv\": \"FutureBookings\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/No-Show%20Report0.csv\": \"NoShowReport\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/Receipt%20Transactions0.csv\": \"ReceiptTransactions\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/Service%20Listing0.csv\": \"ServiceListing\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/hair_salon_no_show_wrangled_df.csv\": \"HairSalonNoShowWrangled\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d842d3-65b9-42b4-8825-db20a1566ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: CSV URL for ClientCancellations\n",
    "csv_url = \"https://storage.googleapis.com/data_migration_pr1/Client%20Cancellations0.csv\"\n",
    "table_name = \"ClientCancellations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8873072-1c7b-4070-af98-f9cda68ee31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load CSV using pandas\n",
    "df = pd.read_csv(csv_url)\n",
    "\n",
    "# Step 4: Clean NaNs and ensure compatibility\n",
    "df = df.where(pd.notnull(df), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f1f0ad-1c7e-4f84-922d-6703b086fc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build dynamic INSERT statement\n",
    "columns = df.columns.tolist()\n",
    "placeholders = \", \".join([\"?\"] * len(columns))\n",
    "col_names = \", \".join(f\"[{col}]\" for col in columns)\n",
    "insert_sql = f\"INSERT INTO {table_name} ({col_names}) VALUES ({placeholders})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e7306c-6303-4a8d-a3b9-8b81456564a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“¥ Inserting rows into ClientCancellations...\n",
      " Insert failed for row 13: {'CancelDate': '06/30/2018', 'Code': 'TAMA01', 'Service1': 'SHCW', 'Staff': 'KELLY', 'BookingDate': '06/30/2018', 'CanceledBy': 'BECKY', 'Days1': nan}\n",
      " Insert failed for row 14: {'CancelDate': '06/30/2018', 'Code': 'TAMA01', 'Service1': 'CBAL', 'Staff': 'KELLY', 'BookingDate': '06/30/2018', 'CanceledBy': 'BECKY', 'Days1': nan}\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Insert row by row\n",
    "print(f\"\\nðŸ“¥ Inserting rows into {table_name}...\")\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        values = tuple(row[col] for col in columns)\n",
    "        cursor.execute(insert_sql, values)\n",
    "    except Exception as e:\n",
    "        print(f\" Insert failed for row {idx + 1}: {row.to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f8b4a9c-6363-41e4-b3ee-e0cd1023d744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Inserting rows into FutureBookings...\n",
      " Insert complete for FutureBookings with 0 errors.\n",
      "\n",
      " Inserting rows into NoShowReport...\n",
      " Insert complete for NoShowReport with 0 errors.\n",
      "\n",
      " Inserting rows into ReceiptTransactions...\n",
      " Insert complete for ReceiptTransactions with 0 errors.\n",
      "\n",
      " Inserting rows into ServiceListing...\n",
      " Insert complete for ServiceListing with 0 errors.\n",
      "\n",
      " Inserting rows into HairSalonNoShowWrangled...\n",
      " Insert complete for HairSalonNoShowWrangled with 0 errors.\n"
     ]
    }
   ],
   "source": [
    "# URLs and matching table names (excluding ClientCancellations)\n",
    "csv_table_mapping = {\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/Future%20Bookings%20(All%20Clients)0.csv\": \"FutureBookings\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/No-Show%20Report0.csv\": \"NoShowReport\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/Receipt%20Transactions0.csv\": \"ReceiptTransactions\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/Service%20Listing0.csv\": \"ServiceListing\",\n",
    "    \"https://storage.googleapis.com/data_migration_pr1/hair_salon_no_show_wrangled_df.csv\": \"HairSalonNoShowWrangled\"\n",
    "}\n",
    "\n",
    "# Insert data into each table\n",
    "for url, table_name in csv_table_mapping.items():\n",
    "    print(f\"\\n Inserting rows into {table_name}...\")\n",
    "    df = pd.read_csv(url)\n",
    "    df.fillna(\"\", inplace=True)\n",
    "\n",
    "    columns = df.columns.tolist()\n",
    "    placeholders = ', '.join(['?'] * len(columns))\n",
    "    insert_sql = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders})\"\n",
    "\n",
    "    insert_errors = 0\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            cursor.execute(insert_sql, tuple(row))\n",
    "        except Exception as e:\n",
    "            print(f\" Insert failed for row {i + 1}: {row.to_dict()}\")\n",
    "            print(f\"   Error: {e}\")\n",
    "            insert_errors += 1\n",
    "\n",
    "    conn.commit()\n",
    "    print(f\" Insert complete for {table_name} with {insert_errors} errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d20b3-873d-4958-bb70-736800131f89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
